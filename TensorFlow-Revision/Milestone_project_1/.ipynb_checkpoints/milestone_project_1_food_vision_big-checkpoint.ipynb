{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584d4d69",
   "metadata": {},
   "source": [
    "# Milestone Project 1: Food Vision Big\n",
    "\n",
    "See the annotated version of this notebook on mrdbourke's [Github](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcde035",
   "metadata": {},
   "source": [
    "## Check GPU\n",
    "\n",
    "Google Colab offers free GPUs, however, not all of them, are compatible with mixed precision training.\n",
    "\n",
    "If we're using our own hardware, our GPU needs a score of 7.0+ (see [here](https://developer.nvidia.com/cuda-gpus#compute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf25811d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU (UUID: GPU-9a78f125-7401-3262-149a-8818757a31e6)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5e0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546af8a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9af4fa",
   "metadata": {},
   "source": [
    "## Get helper functions\n",
    "\n",
    "In past modules, we've created a bunch of helper functions to do small tasks required for our notebooks.\n",
    "\n",
    "The script we've got is available on [GitHub](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c7141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -O helper_functions.py https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1264d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import series of helper functions\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8515f2b",
   "metadata": {},
   "source": [
    "## Use TensorFlow Datasets to Download Data\n",
    "\n",
    "If you want to get an overview of TensorFlow Datasets (TFDS), read the [guide](https://www.tensorflow.org/datasets/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bc9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tensorflow datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658f50b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available datasets\n",
    "datasets_list = tfds.list_builders()\n",
    "\"food101\" in datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28688a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\ARGF0RCE-LAPTOP\\tensorflow_datasets\\food101\\2.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac5a95fba234f9cabbf957fc2b01240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc396b34b8f41d483cf03103ccb751a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b36ae0d08bd41f28f4d46483f2b852c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in the data (takes 5-6 minutes)\n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
    "                                            split=[\"train\", \"validation\"],\n",
    "                                            shuffle_files=True,\n",
    "                                            as_supervised=True, # Gets data returned as a tuple\n",
    "                                            with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7e39f",
   "metadata": {},
   "source": [
    "## Exploring Food101 dataset from TFDS\n",
    "\n",
    "To become one with the data, we want to find:\n",
    "* Class names\n",
    "* The shape of our input data\n",
    "* The datatype of our input data\n",
    "* What the labels look like\n",
    "* Do the labels match up with the class names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5996a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = ds_info.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one sample of the train data\n",
    "train_one_sample = train_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1893337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output info about our training sample\n",
    "for image, label in train_one_sample:\n",
    "    print(f\"\"\"\n",
    "    Image_shape: {image.shape}\n",
    "    Image_datatype: {image.dtype}\n",
    "    Target class from Food101: {label}\n",
    "    Class name (str form): {class_names[label.numpy()]}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does our image tensor look like\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a22873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reduce_min(image), tf.reduce_max(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e38662",
   "metadata": {},
   "source": [
    "### Plot an image TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image tensor\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.title(class_names[label.numpy()])\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab80e8",
   "metadata": {},
   "source": [
    "## Create preprocessing functions for our data\n",
    "\n",
    "What we know about our data:\n",
    "* In `uint8` datatype\n",
    "* Comprised of all different size tensors\n",
    "* Not normalized\n",
    "\n",
    "What we know models like:\n",
    "* Data in `float32` dtype\n",
    "* For batches, TensorFlow likes all tensors of same size in a batch\n",
    "* Valus Normalized (values between 0 & 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47388a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function for preprocessing images\n",
    "def preprocess_img(image, label, img_shape=512):\n",
    "    image = tf.image.resize(image, [img_shape, img_shape])\n",
    "    return tf.cast(image, tf.float32), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4009b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess a single sample and check the output\n",
    "preprocessed_img = preprocess_img(image, label)[0]\n",
    "preprocessed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bbed4e",
   "metadata": {},
   "source": [
    "## Batch & Prepare datasets\n",
    "\n",
    "We're going to make our data input pipeline run really fast.\n",
    "\n",
    "For more resources on this, I'd highly recommend going through the following [guide](https://www.tensorflow.org/guide/data_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map preprocessing function to training (and parallelize)\n",
    "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Shuffle train_data and turn into batches and prefetch it\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Map preprocessing function to test data\n",
    "test_data = test_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db6ea8",
   "metadata": {},
   "source": [
    "## Create modelling callbacks\n",
    "\n",
    "We're going to create a couple of callbacks to help us while our model trains:\n",
    "* TensorBoard callback\n",
    "* ModelCheckpoint Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modelcheckpoint callback\n",
    "checkpoint_path = 'model_checkpoints/cp.ckpt'\n",
    "model_chekpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                     monitor=\"val_acc\",\n",
    "                                                     save_best_only=True,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4c224",
   "metadata": {},
   "source": [
    "## Setup mixed precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f533fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab812f58",
   "metadata": {},
   "source": [
    "## Build feature extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Create base model\n",
    "INPUT_SHAPE = (512, 512, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create functional model\n",
    "inputs = layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
    "# x = preprocessing.Rescaling(1./255)(inputs) # Don't need this layer\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(len(class_names))(x)\n",
    "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf358d4",
   "metadata": {},
   "source": [
    "## Fit the feature extraction model\n",
    "\n",
    "If our goal is to fine-tune a pretrainied model, the general order of doing things is:\n",
    "1. Build a feature extraction model\n",
    "2. Fine-tune some of the frozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with callbacks\n",
    "history_101_food_classes_feature_extract = model.fit(train_data,\n",
    "                                                    epochs=3,\n",
    "                                                    steps_per_epoch=len(train_data),\n",
    "                                                    validation_data=test_data,\n",
    "                                                    validation_steps=int(0.15*len(test_data)),\n",
    "                                                    callbacks=[create_tensorboard_callback(dir_name=\"training_logs\",\n",
    "                                                                                          experiment_name=\"effnetb0_food101_feature_extract\"),\n",
    "                                                              model_chekpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e1750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7292d0bdde5a871dcb77ccba06362ce6c47ed8c13f7c7223b6182d3b2d3842c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
